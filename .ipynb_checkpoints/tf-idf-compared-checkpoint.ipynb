{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tfidfの実装の比較\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概要\n",
    "\n",
    "#### tf-idfの説明\n",
    "- tf-idfは、文書中の単語に関する重みの一種であり、主に情報検索や文章要約などの分野で利用される。\n",
    "- tf-idfは、tf（英: Term Frequency、単語の出現頻度）とidf（英: Inverse Document Frequency、逆文書頻度）の二つの指標にもとづいて計算される。\n",
    "\n",
    "#### 式とその説明\n",
    "$$tfidf_{i,j}=tf_{i,j} \\cdot idf_{i}$$\n",
    "$$tf_{i,j}=\\frac{n_{i,j}}{\\sum_{k}n_{k,j}}$$\n",
    "$$idf_i = log \\frac{|D|}{|\\{d:d\\ni t_i\\}|}$$\n",
    "\n",
    "$n_{i,j}$は単語 $t_{i}$ の文書 $d_{j}$ における出現回数、 $\\sum _{k}n_{k,j}$ は文書 $d_{j}$ におけるすべての単語の出現回数の和、$|D|$ は総文書数、$|\\{d:d\\ni t_{i}\\}|$ は単語 $t_{i}$ を含む文書数である。そのため、idfは一種の一般語フィルタとして働き、多くの文書に出現する語（一般的な語）は重要度が下がり、特定の文書にしか出現しない単語の重要度を上げる役割を果たす。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brownコーパスの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'dan', u'morgan', u'told', u'would', u'forget', u'ann', u'turner', u'well', u'rid', u'certainly']\n",
      "[u'northern', u'liberals', u'chief', u'supporters', u'civil', u'rights', u'integration', u'also', u'led', u'nation']\n",
      "[u'assembly', u'session', u'brought', u'much', u'good', u'general', u'assembly', u'adjourns', u'today', u'performed']\n",
      "[u'thirty-three', u'scotty', u'go', u'back', u'school', u'parents', u'talked', u'seriously', u'lengthily', u'doctor']\n",
      "[u'office', u'business', u'economics', u'(', u'obe', u')', u'u.s.', u'department', u'commerce', u'provides']\n",
      "[u'often', u'beginning', u'bodybuilder', u'training', u'secretly', u'either', u'parents', u\"don't\", u'want', u'sonny-boy']\n",
      "[u'among', u'hinkle', u'identified', u'photograph', u'barco', u'!', u'!', u'seems', u'barco', u'fancying']\n",
      "[u'1', u'introduction', u'recently', u'become', u'practical', u'use', u'radio', u'emission', u'moon', u'planets']\n",
      "[u'american', u'romance', u'almost', u'nothing', u'rates', u'higher', u'movie', u'men', u'called', u'meeting']\n",
      "[u'thirty-eight', u'patients', u'bus', u'morning', u'left', u'hanover', u'disturbed', u'hallucinating', u'interne', u'nurse']\n",
      "[u'fulton', u'county', u'grand', u'jury', u'said', u'friday', u'investigation', u\"atlanta's\", u'recent', u'primary']\n",
      "[u'result', u'although', u'still', u'make', u'use', u'distinction', u'much', u'confusion', u'meaning', u'basic']\n",
      "[u'news', u'nathan', u'milstein', u'wizard', u'violin', u'certainly', u'orchestra', u'hall', u'played', u'countless']\n",
      "[u'neither', u'liked', u'disliked', u'old', u'man', u'could', u'broken', u'bell', u'church', u'tower']\n",
      "[u'knew', u'self', u'free', u'grok', u'ever', u'closer', u'brothers', u'merge', u'without', u'let']\n",
      "\n",
      "[u'!', u'$.027', u'$.07', u'$.076', u'$.09', u'$1,000', u'$1,000,000', u'$1,250,000', u'$1,500', u'$1,750,000']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import nltk.corpus as nc\n",
    "import time\n",
    "\n",
    "stopwords = set(nc.stopwords.words(\"english\")) | set(['','.',',','\"\"',\"''\",'``'])\n",
    "\n",
    "genres = nc.brown.categories()\n",
    "docs = []\n",
    "vocab = set([])\n",
    "for genre in genres:\n",
    "    words = nc.brown.words(categories=genre)\n",
    "    doc = []\n",
    "    for w in words:\n",
    "        if w.lower() not in stopwords:\n",
    "            doc.append(w.lower())\n",
    "\n",
    "    doc = doc[0:5000]\n",
    "    d_vocab = set(doc)\n",
    "    docs.append(doc)\n",
    "    vocab |= d_vocab\n",
    "        \n",
    "vocab_list = sorted(list(vocab))\n",
    "\n",
    "for doc in docs:\n",
    "    print doc[0:10]\n",
    "\n",
    "print \"\"\n",
    "print vocab_list[0:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nltkによる実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.807 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "import nltk.text as nt\n",
    "\n",
    "col = nt.TextCollection(docs)\n",
    "\n",
    "all_tfidfs = []\n",
    "for doc in docs:\n",
    "    tfidfs = []\n",
    "    for w in vocab_list:\n",
    "        tfidf = col.tf_idf(w,doc)\n",
    "        tfidfs.append(tfidf)\n",
    "        \n",
    "    all_tfidfs.append(tfidfs)\n",
    "\n",
    "end = time.time()\n",
    "elapsed_time = end - start\n",
    "print \"%.3f sec\"%(elapsed_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpyによる実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def maketfidfmatrix(docvocabfreqmatrix):\n",
    "    idfmatrix  = np.zeros(docvocabfreqmatrix.shape, dtype=np.float)\n",
    "\n",
    "    # make tfmatrix\n",
    "    wsum = np.sum(docvocabfreqmatrix, axis=1)\n",
    "    tfmatrix  = np.zeros(docvocabfreqmatrix.shape, dtype=np.float)\n",
    "    for i in range(wsum.shape[0]):\n",
    "        tfmatrix[i,:] = docvocabfreqmatrix[i,:]/wsum[i]\n",
    "\n",
    "    # make idfarray\n",
    "    lenD, lenV = docvocabfreqmatrix.shape\n",
    "    \n",
    "    idfarray = np.zeros((1,lenV), dtype=np.float)\n",
    "    for j in xrange(lenV):\n",
    "        idfarray[0,j] = np.log((lenD+1)/(np.where(docvocabfreqmatrix[:,j]>0)[0].shape[0]+1))\n",
    "\n",
    "#    print idfarray\n",
    "#    print tfmatrix\n",
    "#    freqarray = np.sum(docvocabfreqmatrix, axis=0)\n",
    "\n",
    "    tfidfmatrix =  tfmatrix * idfarray\n",
    "    return tfidfmatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.566 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "import numpy as np\n",
    "\n",
    "freq_array = np.zeros((len(docs),len(vocab)), dtype=np.float)\n",
    "\n",
    "for i,doc in enumerate(docs):\n",
    "    l = len(doc)\n",
    "    for j in xrange(0,l,1):\n",
    "        w = doc[j]\n",
    "        idx = vocab_list.index(w)\n",
    "        freq_array[i,idx] += 1.0\n",
    "\n",
    "tfidf_matrix = maketfidfmatrix(freq_array)\n",
    "\n",
    "                      \n",
    "end = time.time()\n",
    "elapsed_time = end - start\n",
    "print \"%.3f sec\"%(elapsed_time)\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004342168996253753, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.00012406197132153578, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0004962478852861431, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0010832200804408842, 0.0016248301206613258, 0.0005416100402204421, 0.0005416100402204421]\n",
      "[0.00322561125435993, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.003845921110967609, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.001116557741893822, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.00024812394264307156, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0008684337992507505, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0006203098566076789, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.004342168996253753, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0023571774551091797, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(docs)):\n",
    "    print all_tfidfs[i][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.00083178,  0.00124766,  0.00041589,  0.00041589],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix[:,0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pythonによるノーマルな実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_tfidf(vocab_list,docs):\n",
    "    import math\n",
    "    import collections as cl\n",
    "    # idf\n",
    "    idf = {}\n",
    "    D = len(docs) # 文書数\n",
    "\n",
    "    dfDic = cl.defaultdict(float)\n",
    "    \n",
    "    tfDics = []\n",
    "    for doc in docs:\n",
    "        tfDic = cl.defaultdict(float)\n",
    "        d_vocab = list(set(doc))\n",
    "        _sum = float(len(doc))\n",
    "        for w in d_vocab:\n",
    "            dfDic[w] += 1.0\n",
    "        for w in doc:\n",
    "            tfDic[w] += 1.0/_sum\n",
    "        tfDics.append(tfDic)\n",
    "        \n",
    "    idfDic = {}\n",
    "    for w in vocab_list:\n",
    "        idfDic[w] = math.log((D+1) / (dfDic[w]+1))\n",
    "\n",
    "    #tfidf\n",
    "    all_tfidfs = []\n",
    "    for i in range(len(docs)):\n",
    "        tfidfs = []\n",
    "        tfDic = tfDics[i]\n",
    "        for w in vocab_list:\n",
    "            tfidf = tfDic[w]*idfDic[w]\n",
    "            tfidfs.append(tfidf)\n",
    "        all_tfidfs.append(tfidfs)\n",
    "    \n",
    "    return all_tfidfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.235 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "all_tfidfs = calc_tfidf(vocab_list,docs)\n",
    "    \n",
    "end = time.time()\n",
    "elapsed_time = end - start\n",
    "print \"%.3f sec\"%(elapsed_time)\n",
    "                      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0040275490143249345, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.00011507282898071235, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.00046029131592284945, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0008317766166719343, 0.0012476649250079015, 0.00041588830833596716, 0.00041588830833596716]\n",
      "[0.002991893553498521, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0035672576984020843, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0010356554608264114, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0002301456579614247, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0008055098028649866, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0005753641449035618, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0040275490143249345, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.002186383750633533, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(docs)):\n",
    "    print all_tfidfs[i][0:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
